"""
–ü—Ä–æ—Å—Ç–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è Windows –±–µ–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""
import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Callable
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_distances
import shutil
import os

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
IMG_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

class SimpleFaceRecognition:
    """–ü—Ä–æ—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü —Å OpenCV."""
    
    def __init__(self):
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–∞—Å–∫–∞–¥ –•–∞–∞—Ä–∞ –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        print("‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–∞ –ø—Ä–æ—Å—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü")
    
    def detect_faces_simple(self, img: np.ndarray) -> List[np.ndarray]:
        """–ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü —Å –ø–æ–º–æ—â—å—é OpenCV Haar Cascade."""
        try:
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ—Ä—ã–π
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
            faces = self.face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(30, 30)
            )
            
            face_images = []
            for (x, y, w, h) in faces:
                # –ò–∑–≤–ª–µ–∫–∞–µ–º –ª–∏—Ü–æ
                face_img = img[y:y+h, x:x+w]
                if face_img.size > 0:
                    face_images.append(face_img)
            
            return face_images
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏ –ª–∏—Ü: {e}")
            return []
    
    def extract_embedding_simple(self, face_img: np.ndarray) -> np.ndarray:
        """–ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –ª–∏—Ü–∞."""
        try:
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–≥–æ
            face_resized = cv2.resize(face_img, (96, 96))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å–µ—Ä—ã–π
            gray = cv2.cvtColor(face_resized, cv2.COLOR_BGR2GRAY)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            normalized = gray.astype(np.float32) / 255.0
            
            # –ü—Ä–æ—Å—Ç–æ–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ (–º–æ–∂–Ω–æ –∑–∞–º–µ–Ω–∏—Ç—å –Ω–∞ –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω–æ–µ)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤ –∫–∞–∫ –ø—Ä–æ—Å—Ç–æ–π –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä
            sobelx = cv2.Sobel(normalized, cv2.CV_64F, 1, 0, ksize=3)
            sobely = cv2.Sobel(normalized, cv2.CV_64F, 0, 1, ksize=3)
            
            # –í—ã—á–∏—Å–ª—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤
            hist_x = cv2.calcHist([sobelx], [0], None, [32], [0, 256])
            hist_y = cv2.calcHist([sobely], [0], None, [32], [0, 256])
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—ã
            features = np.concatenate([hist_x.flatten(), hist_y.flatten()])
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
            features = features / (np.linalg.norm(features) + 1e-8)
            
            return features
            
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {e}")
            return np.zeros(64)  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä

def build_plan_simple(
    input_dir: Path, 
    n_clusters: int = 8,
    progress_callback: Optional[Callable] = None
) -> Dict:
    """–ü—Ä–æ—Å—Ç–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–ª–∞–Ω–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏."""
    
    if progress_callback:
        progress_callback(0, "üöÄ [SIMPLE] –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–π –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏...")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
    recognizer = SimpleFaceRecognition()
    
    # –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    image_files = []
    for ext in IMG_EXTS:
        image_files.extend(input_dir.glob(f"*{ext}"))
        image_files.extend(input_dir.glob(f"*{ext.upper()}"))
    
    if progress_callback:
        progress_callback(0, f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    if not image_files:
        return {"cluster_map": {}, "embeddings": [], "image_paths": []}
    
    # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    embeddings = []
    image_paths = []
    
    for i, img_path in enumerate(image_files):
        if progress_callback:
            progress = int((i / len(image_files)) * 60)
            progress_callback(progress, f"üì∑ –ê–Ω–∞–ª–∏–∑: {progress}% ({i+1}/{len(image_files)})")
        
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = cv2.imread(str(img_path))
            if img is None:
                continue
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
            faces = recognizer.detect_faces_simple(img)
            
            if not faces:
                continue
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞
            for face in faces:
                embedding = recognizer.extract_embedding_simple(face)
                embeddings.append(embedding)
                image_paths.append(str(img_path))
                
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path}: {e}")
            continue
    
    if not embeddings:
        if progress_callback:
            progress_callback(100, "‚ùå –õ–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        return {"cluster_map": {}, "embeddings": [], "image_paths": []}
    
    if progress_callback:
        progress_callback(70, f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(embeddings)} —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–∑ {len(image_files)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    if progress_callback:
        progress_callback(75, f"üîÑ Agglomerative Clustering {len(embeddings)} –ª–∏—Ü...")
    
    try:
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º AgglomerativeClustering
        clustering = AgglomerativeClustering(
            n_clusters=min(n_clusters, len(embeddings)),
            metric='precomputed',
            linkage='average'
        )
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–∞—Ç—Ä–∏—Ü—É —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        dist_matrix = cosine_distances(embeddings)
        
        # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
        labels = clustering.fit_predict(dist_matrix)
        
        if progress_callback:
            progress_callback(85, f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(set(labels))} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º –∫–∞—Ä—Ç—É –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
        cluster_map = {}
        for i, (label, img_path) in enumerate(zip(labels, image_paths)):
            if label not in cluster_map:
                cluster_map[label] = []
            cluster_map[label].append(img_path)
        
        if progress_callback:
            progress_callback(90, f"‚úÖ –°–æ–∑–¥–∞–Ω–æ {len(cluster_map)} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
        
        return {
            "cluster_map": cluster_map,
            "embeddings": embeddings,
            "image_paths": image_paths
        }
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        if progress_callback:
            progress_callback(100, f"‚ùå –û—à–∏–±–∫–∞ –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏: {e}")
        return {"cluster_map": {}, "embeddings": [], "image_paths": []}

def distribute_to_folders(plan: Dict, base_dir: Path, cluster_start: int = 1, progress_callback: Optional[Callable] = None) -> Tuple[int, int, int]:
    """–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞–ø–∫–∞–º."""
    
    if not plan.get("cluster_map"):
        return 0, 0, 0
    
    cluster_map = plan["cluster_map"]
    total_clusters = len(cluster_map)
    
    if progress_callback:
        progress_callback(0, f"üîÑ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {sum(len(files) for files in cluster_map.values())} —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞–ø–∫–∞–º...")
    
    moved_count = 0
    copied_count = 0
    
    for cluster_id, files in cluster_map.items():
        if not files:
            continue
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞
        cluster_folder = base_dir / f"cluster_{cluster_id + cluster_start}"
        cluster_folder.mkdir(exist_ok=True)
        
        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª—ã
        for i, file_path in enumerate(files):
            try:
                src_path = Path(file_path)
                dst_path = cluster_folder / src_path.name
                
                if src_path.exists():
                    if src_path.parent == cluster_folder.parent:
                        # –ï—Å–ª–∏ —Ñ–∞–π–ª —É–∂–µ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø–∞–ø–∫–µ, –∫–æ–ø–∏—Ä—É–µ–º
                        shutil.copy2(src_path, dst_path)
                        copied_count += 1
                    else:
                        # –ü–µ—Ä–µ–º–µ—â–∞–µ–º —Ñ–∞–π–ª
                        shutil.move(str(src_path), str(dst_path))
                        moved_count += 1
                
                if progress_callback:
                    progress = int(((i + 1) / len(files)) * 100)
                    progress_callback(progress, f"üìÅ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤: {progress}% ({i+1}/{len(files)})")
                    
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏—è {file_path}: {e}")
                continue
    
    if progress_callback:
        progress_callback(100, f"‚úÖ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ: {moved_count} –ø–µ—Ä–µ–º–µ—â–µ–Ω–æ, {copied_count} —Å–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ")
    
    return moved_count, copied_count, total_clusters

def process_group_folder(folder_path: Path, progress_callback: Optional[Callable] = None) -> Dict:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å –≥—Ä—É–ø–ø–æ–π –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π."""
    return build_plan_simple(folder_path, progress_callback=progress_callback)
