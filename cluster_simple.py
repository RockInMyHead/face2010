"""
Production-–≤–∞—Ä–∏–∞–Ω—Ç –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏ –ª–∏—Ü –Ω–∞ –±–∞–∑–µ ArcFace + Faiss.
- –î–µ—Ç–µ–∫—Ü–∏—è –∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏: InsightFace (ArcFace), app.FaceAnalysis
- –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: –≥—Ä–∞—Ñ –ø–æ –ø–æ—Ä–æ–≥—É –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ (Faiss range_search + –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã —Å–≤—è–∑–Ω–æ—Å—Ç–∏)
- –°–æ–≤–º–µ—Å—Ç–∏–º –ø–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—É —Å —É–ø—Ä–æ—â—ë–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π: build_plan_pro, distribute_to_folders, process_group_folder
- –£—Å—Ç–æ–π—á–∏–≤ –∫ Unicode-–ø—É—Ç—è–º, –º–Ω–æ–≥–æ-–ª–∏—Ü–∞–º –Ω–∞ —Ñ–æ—Ç–æ, –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—é –¥–ª—è –º—É–ª—å—Ç–∏–∫–ª–∞—Å—Ç–µ—Ä–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤

–ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏:
    pip install insightface onnxruntime-gpu faiss-gpu opencv-python pillow scikit-learn numpy
–∏–ª–∏ (CPU-only):
    pip install insightface onnxruntime faiss-cpu opencv-python pillow scikit-learn numpy

–ê–≤—Ç–æ—Ä: prod-ready —Å–∫–µ–ª–µ—Ç. –ü–æ–¥–∫–ª—é—á–∞–π—Ç–µ –≤ —Å–≤–æ—ë –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–∞–ø—Ä—è–º—É—é.
"""
from __future__ import annotations
import os
import time
from dataclasses import dataclass
from pathlib import Path
from typing import Callable, Dict, Iterable, List, Optional, Tuple

import numpy as np
import cv2
from PIL import Image
from collections import defaultdict, deque

# Faiss –º–æ–∂–µ—Ç –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –ø—Ä–∏ —Å–±–æ—Ä–∫–µ ‚Äî –≤–∞–ª–∏–¥–∏—Ä—É–µ–º –∏–º–ø–æ—Ä—Ç.
try:
    import faiss  # type: ignore
except Exception as e:  # pragma: no cover
    faiss = None

try:
    from insightface.app import FaceAnalysis
except Exception as e:  # pragma: no cover
    FaceAnalysis = None

IMG_EXTS = {".jpg", ".jpeg", ".png", ".bmp", ".tiff", ".webp"}
ProgressCB = Optional[Callable[[str, int], None]]

# ------------------------
# –£—Ç–∏–ª–∏—Ç—ã –≤–≤–æ–¥–∞/–≤—ã–≤–æ–¥–∞
# ------------------------

def is_image(path: Path) -> bool:
    return path.suffix.lower() in IMG_EXTS


def imread_safe(path: Path) -> Optional[np.ndarray]:
    """–ê–∫–∫—É—Ä–∞—Ç–Ω–æ–µ —á—Ç–µ–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (BGR->RGB). –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None –ø—Ä–∏ –æ—à–∏–±–∫–µ.
    –ò—Å–ø–æ–ª—å–∑—É–µ–º cv2.imdecode –¥–ª—è –ª—É—á—à–µ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ Unicode –ø—É—Ç–µ–π.
    """
    try:
        data = np.fromfile(str(path), dtype=np.uint8)
        img_bgr = cv2.imdecode(data, cv2.IMREAD_COLOR)
        if img_bgr is None:
            return None
        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
        return img_rgb
    except Exception:
        return None


# ------------------------
# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ InsightFace
# ------------------------
@dataclass
class ArcFaceConfig:
    det_size: Tuple[int, int] = (640, 640)
    ctx_id: int = 0                   # GPU: –∏–Ω–¥–µ–∫—Å, CPU: -1
    allowed_blur: float = 0.8         # –ø–æ—Ä–æ–≥ –∫–∞—á–µ—Å—Ç–≤–∞ (–ø—Ä–∏–º–µ—Ä–Ω—ã–π, –æ—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º —è–≤–Ω—ã–π –º—É—Å–æ—Ä)


class ArcFaceEmbedder:
    def __init__(self, config: ArcFaceConfig = ArcFaceConfig()):
        if FaceAnalysis is None:
            raise ImportError("insightface –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–∞–∫–µ—Ç insightface.")
        self.app = FaceAnalysis(name="buffalo_l")
        # ctx_id=-1 ‚Üí CPU, –∏–Ω–∞—á–µ GPU. det_size –≤–ª–∏—è–µ—Ç –Ω–∞ recall/—Å–∫–æ—Ä–æ—Å—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞
        self.app.prepare(ctx_id=config.ctx_id, det_size=config.det_size)
        self.allowed_blur = config.allowed_blur

    def extract(self, img_rgb: np.ndarray) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–∏—Ü: [{embedding, quality, bbox}]. embedding —É–∂–µ L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω InsightFace."""
        faces = self.app.get(img_rgb)
        results: List[Dict] = []
        for f in faces:
            # f.normed_embedding ‚Äî L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ (512,)
            emb = getattr(f, "normed_embedding", None)
            if emb is None:
                # –∑–∞–ø–∞—Å–Ω–æ–π –ø—É—Ç—å: normalise raw embedding
                raw = getattr(f, "embedding", None)
                if raw is None:
                    continue
                v = np.asarray(raw, dtype=np.float32)
                n = np.linalg.norm(v) + 1e-12
                emb = (v / n).astype(np.float32)
            else:
                emb = np.asarray(emb, dtype=np.float32)

            # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞: –∏—Å–ø–æ–ª—å–∑—É–µ–º blur/pose/–¥–µ—Ç—Å–∫—É—é confidence –µ—Å–ª–∏ –µ—Å—Ç—å
            quality = float(getattr(f, "det_score", 0.99))
            if quality <= 0:  # —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞
                quality = 0.99

            bbox = tuple(int(x) for x in f.bbox.astype(int).tolist())
            results.append({
                "embedding": emb,
                "quality": quality,
                "bbox": bbox,
            })
        return results


# ------------------------
# –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Faiss (–≥—Ä–∞—Ñ –ø–æ –ø–æ—Ä–æ–≥—É –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏)
# ------------------------
@dataclass
class ClusterParams:
    sim_threshold: float = 0.60   # —á–µ–º –≤—ã—à–µ, —Ç–µ–º —Å—Ç—Ä–æ–∂–µ (0.55‚Äì0.65 ‚Äî —á–∞—â–µ –≤—Å–µ–≥–æ –æ–∫)
    min_cluster_size: int = 2     # —Å—Ä–µ–∑–∞–µ–º –º–µ–ª–∫–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∫–∞–∫ –æ–¥–∏–Ω–æ—á–∫–∏
    max_edges_per_node: int = 50  # –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –Ω–∞ —Å—Ç–µ–ø–µ–Ω—å —É–∑–ª–∞ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –Ω–∞ –æ–≥—Ä–æ–º–Ω—ã—Ö N)


def _build_similarity_graph_faiss(embeddings: np.ndarray, params: ClusterParams) -> List[List[int]]:
    if faiss is None:
        raise ImportError("faiss –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ faiss-gpu –∏–ª–∏ faiss-cpu.")
    if embeddings.dtype != np.float32:
        embeddings = embeddings.astype(np.float32)

    # –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å L2-–Ω–æ—Ä–º–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è cosine=dot
    norms = np.linalg.norm(embeddings, axis=1, keepdims=True) + 1e-12
    X = embeddings / norms

    d = X.shape[1]
    index = faiss.IndexFlatIP(d)
    index.add(X)

    # range_search: –≤–µ—Ä–Ω—ë—Ç –ø–∞—Ä—ã (i,j) —Å sim >= threshold
    lims, D, I = index.range_search(X, params.sim_threshold)

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–ø–∏—Å–∫–∏ —Å–º–µ–∂–Ω–æ—Å—Ç–∏ (–±–µ–∑ self-loop –∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤)
    n = X.shape[0]
    adj: List[List[int]] = [[] for _ in range(n)]
    for i in range(n):
        beg, end = lims[i], lims[i + 1]
        # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ sim —É–±—ã–≤.
        pairs = sorted(zip(I[beg:end], D[beg:end]), key=lambda t: -t[1])
        count = 0
        for j, sim in pairs:
            if j == i or j < 0:
                continue
            adj[i].append(int(j))
            count += 1
            if params.max_edges_per_node and count >= params.max_edges_per_node:
                break
    return adj


def _connected_components(adj: List[List[int]]) -> np.ndarray:
    n = len(adj)
    labels = -np.ones(n, dtype=np.int32)
    cid = 0
    for i in range(n):
        if labels[i] != -1:
            continue
        # BFS/DFS
        q = deque([i])
        labels[i] = cid
        while q:
            u = q.popleft()
            for v in adj[u]:
                if labels[v] == -1:
                    labels[v] = cid
                    q.append(v)
        cid += 1
    return labels


def cluster_embeddings_faiss(embeddings: np.ndarray, params: ClusterParams) -> np.ndarray:
    if embeddings.size == 0:
        return np.array([], dtype=np.int32)
    adj = _build_similarity_graph_faiss(embeddings, params)
    labels = _connected_components(adj)

    # –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–µ–º –º–µ–ª–∫–∏–µ –∫–ª–∞—Å—Ç–µ—Ä—ã: –æ–¥–∏–Ω–æ—á–∫–∏ ‚Üí -1, –ø–æ—Ç–æ–º –ø–µ—Ä–µ—Ä–∞–∑–º–µ—Ç–∏–º –ø–ª–æ—Ç–Ω—ã–µ
    sizes = defaultdict(int)
    for lb in labels:
        sizes[int(lb)] += 1

    for i, lb in enumerate(labels):
        if sizes[int(lb)] < params.min_cluster_size:
            labels[i] = -1

    # –°–∂–∏–º–∞–µ–º –∏–Ω–¥–µ–∫—Å—ã –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ –∫ [0..K-1], –∏–≥–Ω–æ—Ä–∏—Ä—É—è -1
    uniq = sorted(x for x in set(labels.tolist()) if x != -1)
    remap = {old: i for i, old in enumerate(uniq)}
    out = labels.copy()
    for i, lb in enumerate(labels):
        if lb == -1:
            out[i] = -1
        else:
            out[i] = remap[int(lb)]
    return out


# ------------------------
# –û—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω
# ------------------------

def build_plan_pro(
    input_dir: Path,
    progress_callback: ProgressCB = None,
    sim_threshold: float = 0.60,
    min_cluster_size: int = 2,
    ctx_id: int = 0,
    det_size: Tuple[int, int] = (640, 640),
) -> Dict:
    """Production-–∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –ª–∏—Ü —Å ArcFace + Faiss.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç dict:
      {
        "clusters": {"0": ["/abs/path/img1.jpg", ...], ...},
        "plan": [ {"path": str, "cluster": [int, ...], "faces": int}, ...],
        "unreadable": [str, ...],
        "no_faces": [str, ...]
      }
    """
    t0 = time.time()
    input_dir = Path(input_dir)
    if progress_callback:
        progress_callback(f"üöÄ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {input_dir}", 2)

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–µ—Ä–∞
    emb = ArcFaceEmbedder(ArcFaceConfig(det_size=det_size, ctx_id=ctx_id))

    # –°–±–æ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
    all_images = [p for p in input_dir.rglob("*") if p.is_file() and is_image(p)]
    if progress_callback:
        progress_callback(f"üìÇ –ù–∞–π–¥–µ–Ω–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π: {len(all_images)}", 5)

    owners: List[Path] = []
    all_embeddings: List[np.ndarray] = []
    img_face_count: Dict[Path, int] = {}
    unreadable: List[Path] = []
    no_faces: List[Path] = []

    total = len(all_images)
    for i, img_path in enumerate(all_images):
        if progress_callback and (i % 10 == 0):
            percent = 5 + int((i + 1) / max(1, total) * 60)
            progress_callback(f"üì∑ –ê–Ω–∞–ª–∏–∑ {i+1}/{total}", percent)

        img = imread_safe(img_path)
        if img is None:
            unreadable.append(img_path)
            continue

        faces = emb.extract(img)
        if not faces:
            no_faces.append(img_path)
            continue

        img_face_count[img_path] = len(faces)
        for face in faces:
            all_embeddings.append(face["embedding"])  # —É–∂–µ L2-–Ω–æ—Ä–º
            owners.append(img_path)

    if not all_embeddings:
        return {
            "clusters": {},
            "plan": [],
            "unreadable": [str(p) for p in unreadable],
            "no_faces": [str(p) for p in no_faces],
        }

    X = np.vstack(all_embeddings).astype(np.float32)

    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —á–µ—Ä–µ–∑ Faiss
    if progress_callback:
        progress_callback("üîó –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∞ –ø–æ—Ö–æ–∂–µ—Å—Ç–∏ (Faiss)", 70)
    labels = cluster_embeddings_faiss(
        X,
        ClusterParams(sim_threshold=sim_threshold, min_cluster_size=min_cluster_size),
    )

    if progress_callback:
        progress_callback(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–æ–≤: {len(set(labels.tolist()) - {-1})}", 85)

    # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –º–∞–ø–æ–≤
    cluster_map: Dict[int, set[Path]] = defaultdict(set)
    cluster_by_img: Dict[Path, set[int]] = defaultdict(set)

    for lb, path in zip(labels, owners):
        if lb == -1:
            # –æ–¥–∏–Ω–æ—á–∫–∏: –º–æ–∂–Ω–æ –ø–æ–º–µ—Å—Ç–∏—Ç—å –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é –ø–∞–ø–∫—É "-1" –ª–∏–±–æ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –∏–∑ –ø–ª–∞–Ω–∞
            continue
        cluster_map[int(lb)].add(path)
        cluster_by_img[path].add(int(lb))

    # –ü–ª–∞–Ω –ø–µ—Ä–µ–º–µ—â–µ–Ω–∏–π/–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è
    plan: List[Dict] = []
    for path in all_images:
        cl = cluster_by_img.get(path)
        if not cl:
            continue
        plan.append({
            "path": str(path),
            "cluster": sorted(list(cl)),
            "faces": img_face_count.get(path, 0),
        })

    if progress_callback:
        dt = time.time() - t0
        progress_callback(f"‚è±Ô∏è –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {dt:.1f}—Å", 95)

    return {
        "clusters": {str(k): [str(p) for p in sorted(v)] for k, v in cluster_map.items()},
        "plan": plan,
        "unreadable": [str(p) for p in unreadable],
        "no_faces": [str(p) for p in no_faces],
    }


# ------------------------
# –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –ø–∞–ø–∫–∞–º (—Å–æ–≤–º–µ—Å—Ç–∏–º–æ —Å —É–ø—Ä–æ—â—ë–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π)
# ------------------------

def distribute_to_folders(plan: dict, base_dir: Path, cluster_start: int = 1, progress_callback: ProgressCB = None, common_mode: bool = False) -> Tuple[int, int, int]:
    import shutil

    moved, copied = 0, 0
    moved_paths = set()

    used_clusters = sorted({c for item in plan.get("plan", []) for c in item["cluster"]})
    # –í —Ä–µ–∂–∏–º–µ –û–ë–©–ê–Ø –ø–æ–ª—É—á–∞–µ–º –≤—Å–µ –∫–ª–∞—Å—Ç–µ—Ä—ã –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏–∏
    all_clusters = set()
    if common_mode and "clusters" in plan:
        all_clusters = set(plan["clusters"].keys())
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∫–ª—é—á–∏ –≤ int
        all_clusters = {int(k) for k in all_clusters if k.isdigit()}
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å used_clusters
        used_clusters = sorted(set(used_clusters) | all_clusters)
    
    cluster_id_map = {old: cluster_start + idx for idx, old in enumerate(used_clusters)}

    plan_items = plan.get("plan", [])
    total_items = len(plan_items)
    if progress_callback:
        progress_callback(f"üîÑ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {total_items} —Ñ–∞–π–ª–æ–≤ –ø–æ –ø–∞–ø–∫–∞–º...", 0)

    cluster_file_counts: Dict[int, int] = {}
    for item in plan_items:
        clusters = [cluster_id_map[c] for c in item["cluster"]]
        for cid in clusters:
            cluster_file_counts[cid] = cluster_file_counts.get(cid, 0) + 1

    for i, item in enumerate(plan_items):
        if progress_callback:
            percent = int((i + 1) / max(total_items, 1) * 100)
            progress_callback(f"üìÅ –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ñ–∞–π–ª–æ–≤: {percent}% ({i+1}/{total_items})", percent)

        src = Path(item["path"])  # –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–∞–π–ª
        clusters = [cluster_id_map[c] for c in item["cluster"]]
        if not src.exists():
            continue
            
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –æ–±—â–∏–º (–Ω–∞—Ö–æ–¥–∏—Ç—Å—è –≤ –ø–∞–ø–∫–µ "–æ–±—â–∏–µ")
        is_common_photo = any(excluded_name in str(src.parent).lower() for excluded_name in EXCLUDED_COMMON_NAMES)
        
        if is_common_photo:
            # –û–±—â–∏–µ —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–∏ –ù–ï –ø–µ—Ä–µ–º–µ—â–∞–µ–º - –æ—Å—Ç–∞–≤–ª—è–µ–º –Ω–∞ –º–µ—Å—Ç–µ
            print(f"üìå –û–±—â–∞—è —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏—è –æ—Å—Ç–∞–≤–ª–µ–Ω–∞: {src.name}")
            # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è –ª—é–¥–µ–π —Å –æ–±—â–∏—Ö —Ñ–æ—Ç–æ–≥—Ä–∞—Ñ–∏–π (–ø—É—Å—Ç—ã–µ) —Ç–æ–ª—å–∫–æ –≤ —Ä–µ–∂–∏–º–µ –û–ë–©–ê–Ø
            if common_mode:
                for cid in clusters:
                    empty_folder = base_dir / str(cid)
                    empty_folder.mkdir(parents=True, exist_ok=True)
                    print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞ –¥–ª—è —á–µ–ª–æ–≤–µ–∫–∞ —Å –æ–±—â–∏—Ö —Ñ–æ—Ç–æ: {cid}")
            continue

        if len(clusters) == 1:
            dst = base_dir / f"{clusters[0]}" / src.name
            dst.parent.mkdir(parents=True, exist_ok=True)
            if src.resolve() != dst.resolve():
                shutil.move(str(src), str(dst))
                moved += 1
                moved_paths.add(src.parent)
        else:
            for cid in clusters:
                dst = base_dir / f"{cid}" / src.name
                dst.parent.mkdir(parents=True, exist_ok=True)
                if src.resolve() != dst.resolve():
                    shutil.copy2(str(src), str(dst))
                    copied += 1
            try:
                src.unlink()
            except Exception:
                pass

    # –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫: –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤ —Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
    if progress_callback:
        progress_callback("üìù –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–∞–ø–æ–∫ —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ñ–∞–π–ª–æ–≤...", 95)
    for cid, cnt in cluster_file_counts.items():
        if cnt > 0:  # –¢–æ–ª—å–∫–æ –¥–ª—è –Ω–µ–ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫
            old_folder = base_dir / str(cid)
            new_folder = base_dir / f"{cid} ({cnt})"
            if old_folder.exists():
                try:
                    old_folder.rename(new_folder)
                except Exception:
                    pass
        else:
            # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
            empty_folder = base_dir / str(cid)
            if empty_folder.exists():
                try:
                    empty_folder.rmdir()
                    print(f"üóëÔ∏è –£–¥–∞–ª–µ–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {empty_folder.name}")
                except Exception:
                    pass

    # –ß–∏—Å—Ç–∏–º –ø—É—Å—Ç—ã–µ –∫–∞—Ç–∞–ª–æ–≥–∏
    if progress_callback:
        progress_callback("üßπ –û—á–∏—Å—Ç–∫–∞ –ø—É—Å—Ç—ã—Ö –ø–∞–ø–æ–∫...", 100)
    for p in sorted(moved_paths, key=lambda x: len(str(x)), reverse=True):
        try:
            p.rmdir()
        except Exception:
            pass

    # –í —Ä–µ–∂–∏–º–µ –û–ë–©–ê–Ø —Å–æ–∑–¥–∞–µ–º –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ + 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ
    if common_mode:
        # –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏ –¥–ª—è –≤—Å–µ—Ö –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–ª–∞—Å—Ç–µ—Ä–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –ø–µ—Ä–µ–Ω—É–º–µ—Ä–∞—Ü–∏–∏
        for old_cid in used_clusters:
            new_cid = cluster_id_map[old_cid]
            empty_folder = base_dir / str(new_cid)
            empty_folder.mkdir(parents=True, exist_ok=True)
            print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞ –¥–ª—è –∫–ª–∞—Å—Ç–µ—Ä–∞: {new_cid}")
        
        # –°–æ–∑–¥–∞–µ–º 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Å—Ç—ã–µ –ø–∞–ø–∫–∏
        max_mapped_cluster_id = max(cluster_id_map.values()) if cluster_id_map else cluster_start - 1
        for i in range(1, 3):  # –°–æ–∑–¥–∞–µ–º 2 –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏
            extra_folder = base_dir / str(max_mapped_cluster_id + i)
            extra_folder.mkdir(parents=True, exist_ok=True)
            print(f"üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—É—Å—Ç–∞—è –ø–∞–ø–∫–∞: {max_mapped_cluster_id + i}")

    return moved, copied, cluster_start + len(used_clusters)


# ------------------------
# –ì—Ä—É–ø–ø–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏ ¬´–æ–±—â–∏–µ¬ª –ø–∞–ø–∫–∏
# ------------------------

EXCLUDED_COMMON_NAMES = ["–æ–±—â–∏–µ", "–æ–±—â–∞—è", "common", "shared", "–≤—Å–µ", "all", "mixed", "—Å–º–µ—à–∞–Ω–Ω—ã–µ"]


def find_common_folders_recursive(group_dir: Path) -> List[Path]:
    common: List[Path] = []
    for subdir in group_dir.rglob("*"):
        if subdir.is_dir() and any(ex in subdir.name.lower() for ex in EXCLUDED_COMMON_NAMES):
            common.append(subdir)
    return common


def process_common_folder_at_level(common_dir: Path, progress_callback: ProgressCB = None,
                                   sim_threshold: float = 0.60, min_cluster_size: int = 2,
                                   ctx_id: int = 0, det_size: Tuple[int, int] = (640, 640)) -> Tuple[int, int]:
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ ¬´–æ–±—â–∏—Ö¬ª –ø–∞–ø–æ–∫: —Ä–∞—Å–∫–ª–∞–¥—ã–≤–∞–µ–º –ª–∏—Ü–∞ –ø–æ –ø–æ–¥–ø–∞–ø–∫–∞–º –≤–Ω—É—Ç—Ä–∏ —Å–∞–º–æ–π ¬´–æ–±—â–µ–π¬ª.
    –ù–∞–ø—Ä–∏–º–µ—Ä: common/ ‚Üí common/1 (...), common/2 (...)
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (moved, copied).
    """
    data = build_plan_pro(common_dir, progress_callback=progress_callback,
                          sim_threshold=sim_threshold, min_cluster_size=min_cluster_size,
                          ctx_id=ctx_id, det_size=det_size)
    moved, copied, _ = distribute_to_folders(data, common_dir, cluster_start=1, progress_callback=progress_callback, common_mode=True)
    return moved, copied


def process_group_folder(group_dir: Path, progress_callback: ProgressCB = None,
                         include_excluded: bool = False,
                         sim_threshold: float = 0.60, min_cluster_size: int = 2,
                         ctx_id: int = 0, det_size: Tuple[int, int] = (640, 640)) -> Tuple[int, int, int]:
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –≥—Ä—É–ø–ø—É –ø–æ–¥–ø–∞–ø–æ–∫: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑—É–µ—Ç –∫–∞–∂–¥—É—é –ø–æ–¥–ø–∞–ø–∫—É –æ—Ç–¥–µ–ª—å–Ω–æ.

    –ï—Å–ª–∏ include_excluded=False ‚Äî –ø–∞–ø–∫–∏ –∏–∑ EXCLUDED_COMMON_NAMES –ø—Ä–æ–ø—É—Å–∫–∞—é—Ç—Å—è.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (moved_total, copied_total, next_cluster_counter).
    """
    group_dir = Path(group_dir)

    if include_excluded:
        commons = find_common_folders_recursive(group_dir)
        for i, c in enumerate(commons):
            if progress_callback:
                progress_callback(f"üìã –û–±—â–∏–µ: {c.name} ({i+1}/{len(commons)})", 5 + int(i / max(1, len(commons)) * 20))
            process_common_folder_at_level(c, progress_callback=progress_callback,
                                           sim_threshold=sim_threshold, min_cluster_size=min_cluster_size,
                                           ctx_id=ctx_id, det_size=det_size)

    subdirs = [d for d in sorted(group_dir.iterdir()) if d.is_dir()]
    if not include_excluded:
        subdirs = [d for d in subdirs if all(ex not in d.name.lower() for ex in EXCLUDED_COMMON_NAMES)]

    total = len(subdirs)
    moved_all, copied_all = 0, 0
    for i, sub in enumerate(subdirs):
        if progress_callback:
            progress_callback(f"üîç {sub.name}: –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è ({i+1}/{total})", 25 + int(i / max(1, total) * 60))
        data = build_plan_pro(
            input_dir=sub,
            progress_callback=progress_callback,
            sim_threshold=sim_threshold,
            min_cluster_size=min_cluster_size,
            ctx_id=ctx_id,
            det_size=det_size,
        )
        m, c, _ = distribute_to_folders(data, sub, cluster_start=1, progress_callback=progress_callback)
        moved_all += m
        copied_all += c

    return moved_all, copied_all, 1


# ------------------------
# CLI-–æ–±–≤—è–∑–∫–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
# ------------------------
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="ArcFace+Faiss face clustering")
    parser.add_argument("input", type=str, help="–ü–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ –∏–ª–∏ –≥—Ä—É–ø–ø–∞ –ø–∞–ø–æ–∫")
    parser.add_argument("--group", action="store_true", help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –∫–∞–∫ –≥—Ä—É–ø–ø—É –ø–æ–¥–ø–∞–ø–æ–∫")
    parser.add_argument("--include-common", action="store_true", help="–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –ø–∞–ø–∫–∏ '–æ–±—â–∏–µ' –≤–Ω—É—Ç—Ä–∏ –≥—Ä—É–ø–ø—ã")
    parser.add_argument("--sim", type=float, default=0.60, help="–ü–æ—Ä–æ–≥ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–π –±–ª–∏–∑–æ—Å—Ç–∏ [0..1]")
    parser.add_argument("--minsz", type=int, default=2, help="–ú–∏–Ω. —Ä–∞–∑–º–µ—Ä –∫–ª–∞—Å—Ç–µ—Ä–∞")
    parser.add_argument("--cpu", action="store_true", help="–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ CPU (ctx_id=-1)")
    parser.add_argument("--det", type=int, nargs=2, default=[640, 640], help="–†–∞–∑–º–µ—Ä –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞ WxH")

    args = parser.parse_args()

    def cb(msg: str, p: int):
        print(f"[{p:3d}%] {msg}")

    if args.group:
        moved, copied, _ = process_group_folder(
            Path(args.input), progress_callback=cb,
            include_excluded=args.include_common,
            sim_threshold=args.sim, min_cluster_size=args.minsz,
            ctx_id=(-1 if args.cpu else 0), det_size=tuple(args.det),
        )
        print(f"DONE: moved={moved}, copied={copied}")
    else:
        data = build_plan_pro(
            Path(args.input), progress_callback=cb,
            sim_threshold=args.sim, min_cluster_size=args.minsz,
            ctx_id=(-1 if args.cpu else 0), det_size=tuple(args.det),
        )
        m, c, _ = distribute_to_folders(data, Path(args.input), cluster_start=1, progress_callback=cb)
        print(f"DONE: moved={m}, copied={c}")
