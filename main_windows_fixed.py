"""
–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è Windows —Å —É–ª—É—á—à–µ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫
"""
import asyncio
import uuid
import os
from pathlib import Path
from typing import Dict, List
from collections import defaultdict
import cv2
import numpy as np
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics.pairwise import cosine_distances
import shutil
from concurrent.futures import ThreadPoolExecutor
import functools

from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.responses import JSONResponse, HTMLResponse
from pydantic import BaseModel
import uvicorn

app = FastAPI()

# –ú–æ–Ω—Ç–∏—Ä—É–µ–º —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏–µ —Ñ–∞–π–ª—ã
app.mount("/static", StaticFiles(directory="static"), name="static")

# –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
app_state = {
    "queue": [],
    "current_tasks": {}
}

# Executor –¥–ª—è —Ñ–æ–Ω–æ–≤—ã—Ö –∑–∞–¥–∞—á
executor = ThreadPoolExecutor(max_workers=2)

# –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã
IMG_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}

class FolderRequest(BaseModel):
    path: str

@app.get("/", response_class=HTMLResponse)
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞."""
    return HTMLResponse(content=open("static/index.html", "r", encoding="utf-8").read())

@app.get("/api/drives")
async def get_drives():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –¥–∏—Å–∫–æ–≤/–∫–æ—Ä–Ω–µ–≤—ã—Ö –ø–∞–ø–æ–∫ –¥–ª—è Windows."""
    drives = []
    # –î–ª—è Windows
    for i in range(ord('C'), ord('Z') + 1):
        drive = f"{chr(i)}:\\"
        if os.path.exists(drive):
            drives.append({"name": drive, "path": drive})
    
    # –î–æ–±–∞–≤–ª—è–µ–º –†–∞–±–æ—á–∏–π —Å—Ç–æ–ª –∏ –î–æ–∫—É–º–µ–Ω—Ç—ã
    desktop_path = Path(os.path.join(os.path.expanduser("~"), "Desktop"))
    documents_path = Path(os.path.join(os.path.expanduser("~"), "Documents"))
    
    if desktop_path.exists():
        drives.insert(0, {"name": "–†–∞–±–æ—á–∏–π —Å—Ç–æ–ª", "path": str(desktop_path)})
    if documents_path.exists():
        drives.insert(0, {"name": "–î–æ–∫—É–º–µ–Ω—Ç—ã", "path": str(documents_path)})

    return {"drives": drives}

@app.get("/api/queue")
async def get_queue():
    return {"queue": app_state["queue"]}

@app.post("/api/queue/add")
async def add_to_queue(request: FolderRequest):
    try:
        folder_path = Path(request.path)
        if not folder_path.exists():
            raise HTTPException(status_code=404, detail="–ü–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
        
        if str(folder_path) not in app_state["queue"]:
            app_state["queue"].append(str(folder_path))
        
        return {"message": f"–ü–∞–ø–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å: {folder_path}"}
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ –æ—á–µ—Ä–µ–¥—å: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/tasks")
async def get_tasks():
    return {"tasks": list(app_state["current_tasks"].values())}

@app.post("/api/process")
async def process_queue(includeExcluded: bool = False):
    try:
        if not app_state["queue"]:
            return {"message": "–û—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞", "task_ids": []}
        
        task_ids = []
        for folder_path in app_state["queue"][:]:
            task_id = str(uuid.uuid4())
            task_ids.append(task_id)
            
            app_state["current_tasks"][task_id] = {
                "status": "pending",
                "progress": 0,
                "message": "–û–∂–∏–¥–∞–Ω–∏–µ...",
                "folder_path": folder_path,
                "include_excluded": includeExcluded
            }
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤ —Ñ–æ–Ω–µ
            asyncio.create_task(process_folder_task(task_id, folder_path, includeExcluded))
        
        app_state["queue"] = []
        return {"message": "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—É—â–µ–Ω–∞", "task_ids": task_ids}
    
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def process_folder_task(task_id: str, folder_path: str, include_excluded: bool):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞–ø–∫–∏ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏"""
    try:
        print(f"üöÄ [TASK] –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É: {folder_path}")
        
        path = Path(folder_path)
        if not path.exists():
            raise Exception(f"–ü—É—Ç—å –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç: {folder_path}")
        
        def progress_callback(progress, message=""):
            if isinstance(progress, (int, float)):
                app_state["current_tasks"][task_id]["progress"] = int(progress)
            if message:
                app_state["current_tasks"][task_id]["message"] = message
                print(f"üìä [TASK] {message}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—é
        loop = asyncio.get_event_loop()
        clustering_func = functools.partial(
            simple_clustering,
            input_dir=path,
            progress_callback=progress_callback
        )
        
        result = await loop.run_in_executor(executor, clustering_func)
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
        app_state["current_tasks"][task_id]["status"] = "completed"
        app_state["current_tasks"][task_id]["progress"] = 100
        app_state["current_tasks"][task_id]["message"] = f"–ì–æ—Ç–æ–≤–æ! –°–æ–∑–¥–∞–Ω–æ –∫–ª–∞—Å—Ç–µ—Ä–æ–≤: {result['clusters']}"
        app_state["current_tasks"][task_id]["result"] = result
        
        print(f"‚úÖ [TASK] –ó–∞–≤–µ—Ä—à–µ–Ω–æ: {folder_path}")
        
    except Exception as e:
        print(f"‚ùå [TASK] –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        app_state["current_tasks"][task_id]["status"] = "error"
        app_state["current_tasks"][task_id]["error"] = str(e)

def simple_clustering(input_dir: Path, progress_callback=None) -> Dict:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è —Å –±–∞–∑–æ–≤—ã–º –¥–µ—Ç–µ–∫—Ç–æ—Ä–æ–º –ª–∏—Ü"""
    print(f"üöÄ [SIMPLE] –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è: {input_dir}")
    
    # –ù–∞–π—Ç–∏ –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
    images = []
    for ext in IMG_EXTS:
        images.extend(input_dir.glob(f"*{ext}"))
        images.extend(input_dir.glob(f"*{ext.upper()}"))
    
    if not images:
        return {"clusters": 0, "moved": 0, "copied": 0}
    
    print(f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    if progress_callback:
        progress_callback(0, f"üìÇ –ù–∞–π–¥–µ–Ω–æ {len(images)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    
    # –ó–∞–≥—Ä—É–∑–∏—Ç—å –¥–µ—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ü OpenCV
    try:
        cascade_path = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        face_cascade = cv2.CascadeClassifier(cascade_path)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω –¥–µ—Ç–µ–∫—Ç–æ—Ä –ª–∏—Ü: {cascade_path}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞: {e}")
        return {"clusters": 0, "moved": 0, "copied": 0}
    
    # –ò–∑–≤–ª–µ—á—å –ª–∏—Ü–∞ –∏ —Å–æ–∑–¥–∞—Ç—å –ø—Ä–æ—Å—Ç—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
    image_faces = defaultdict(list)
    all_embeddings = []
    all_metadata = []
    
    for i, img_path in enumerate(images):
        try:
            # –ü—Ä–æ–≥—Ä–µ—Å—Å
            if progress_callback and i % 5 == 0:
                progress = int((i / len(images)) * 50)  # 0-50% –Ω–∞ –¥–µ—Ç–µ–∫—Ü–∏—é
                progress_callback(progress, f"üì∑ –ê–Ω–∞–ª–∏–∑: {progress}% ({i}/{len(images)})")
            
            # –ß–∏—Ç–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            img = cv2.imread(str(img_path))
            if img is None:
                print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å: {img_path.name}")
                continue
            
            # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
            h, w = img.shape[:2]
            max_size = 800
            if max(h, w) > max_size:
                scale = max_size / max(h, w)
                img = cv2.resize(img, (int(w * scale), int(h * scale)))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ grayscale
            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
            
            # –î–µ—Ç–µ–∫—Ü–∏—è –ª–∏—Ü
            faces = face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(30, 30)
            )
            
            if len(faces) == 0:
                continue
            
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –ª–∏—Ü–∞ —Å–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥
            for (x, y, w, h) in faces:
                # –í—ã—Ä–µ–∑–∞–µ–º –ª–∏—Ü–æ
                face_img = gray[y:y+h, x:x+w]
                
                # –ò–∑–º–µ–Ω—è–µ–º —Ä–∞–∑–º–µ—Ä –¥–æ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ
                face_img = cv2.resize(face_img, (64, 64))
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                face_img = face_img.astype('float32') / 255.0
                
                # –§–ª–∞—Ç—Ç–µ–Ω–∏—Ä—É–µ–º –∫–∞–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥
                embedding = face_img.flatten()
                
                all_embeddings.append(embedding)
                all_metadata.append(str(img_path))
                image_faces[str(img_path)].append(embedding)
        
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {img_path.name}: {e}")
            continue
    
    if len(all_embeddings) == 0:
        print("‚ö†Ô∏è –ù–µ –Ω–∞–π–¥–µ–Ω–æ –ª–∏—Ü")
        return {"clusters": 0, "moved": 0, "copied": 0}
    
    print(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(all_embeddings)} –ª–∏—Ü –∏–∑ {len(image_faces)} –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π")
    if progress_callback:
        progress_callback(50, f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(all_embeddings)} –ª–∏—Ü")
    
    # –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è
    X = np.array(all_embeddings)
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è
    from sklearn.preprocessing import normalize
    X = normalize(X, norm='l2')
    
    # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
    dist_matrix = cosine_distances(X)
    
    # AgglomerativeClustering
    n_clusters = min(8, len(X))  # –ú–∞–∫—Å–∏–º—É–º 8 –∫–ª–∞—Å—Ç–µ—Ä–æ–≤
    clustering = AgglomerativeClustering(
        n_clusters=n_clusters,
        metric='precomputed',
        linkage='average'
    )
    
    if progress_callback:
        progress_callback(60, f"üîÑ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è {len(X)} –ª–∏—Ü...")
    
    labels = clustering.fit_predict(dist_matrix)
    
    print(f"‚úÖ –ö–ª–∞—Å—Ç–µ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {len(set(labels))} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø–æ –∫–ª–∞—Å—Ç–µ—Ä–∞–º
    cluster_map = defaultdict(set)
    for img_path, label in zip(all_metadata, labels):
        cluster_map[label].add(img_path)
    
    # –†–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∞–π–ª—ã
    moved = 0
    copied = 0
    
    for cluster_id, img_paths in cluster_map.items():
        cluster_folder = input_dir / f"cluster_{cluster_id+1}_({len(img_paths)})"
        cluster_folder.mkdir(exist_ok=True)
        
        for img_path in img_paths:
            src = Path(img_path)
            dst = cluster_folder / src.name
            
            try:
                if not dst.exists():
                    shutil.copy2(src, dst)
                    copied += 1
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏—è {src.name}: {e}")
    
    print(f"üì¶ –°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ: {copied}")
    if progress_callback:
        progress_callback(100, f"‚úÖ –ì–æ—Ç–æ–≤–æ! –°–æ–∑–¥–∞–Ω–æ {len(cluster_map)} –∫–ª–∞—Å—Ç–µ—Ä–æ–≤")
    
    return {
        "clusters": len(cluster_map),
        "moved": moved,
        "copied": copied
    }

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–∞ –¥–ª—è Windows...")
    print("üìç –û—Ç–∫—Ä—ã—Ç—å: http://localhost:8000")
    uvicorn.run(app, host="0.0.0.0", port=8000)

